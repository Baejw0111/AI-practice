{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\bjw01\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\random.py:42: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:68.)\n",
            "  return default_generator.manual_seed(seed)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x1a297ece770>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.manual_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Diabetes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>95</td>\n",
              "      <td>60</td>\n",
              "      <td>18</td>\n",
              "      <td>58</td>\n",
              "      <td>23.9</td>\n",
              "      <td>0.260</td>\n",
              "      <td>22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>105</td>\n",
              "      <td>72</td>\n",
              "      <td>29</td>\n",
              "      <td>325</td>\n",
              "      <td>36.9</td>\n",
              "      <td>0.159</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>135</td>\n",
              "      <td>68</td>\n",
              "      <td>42</td>\n",
              "      <td>250</td>\n",
              "      <td>42.3</td>\n",
              "      <td>0.365</td>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>131</td>\n",
              "      <td>68</td>\n",
              "      <td>21</td>\n",
              "      <td>166</td>\n",
              "      <td>33.1</td>\n",
              "      <td>0.160</td>\n",
              "      <td>28</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>103</td>\n",
              "      <td>30</td>\n",
              "      <td>38</td>\n",
              "      <td>83</td>\n",
              "      <td>43.3</td>\n",
              "      <td>0.183</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>5</td>\n",
              "      <td>139</td>\n",
              "      <td>64</td>\n",
              "      <td>35</td>\n",
              "      <td>140</td>\n",
              "      <td>28.6</td>\n",
              "      <td>0.411</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "      <td>122</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22.4</td>\n",
              "      <td>0.207</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>86</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>45.6</td>\n",
              "      <td>1.136</td>\n",
              "      <td>38</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>0</td>\n",
              "      <td>141</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>42.4</td>\n",
              "      <td>0.205</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>0</td>\n",
              "      <td>125</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>22.5</td>\n",
              "      <td>0.262</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>537 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "0              1       95             60             18       58  23.9   \n",
              "1              5      105             72             29      325  36.9   \n",
              "2              0      135             68             42      250  42.3   \n",
              "3              4      131             68             21      166  33.1   \n",
              "4              1      103             30             38       83  43.3   \n",
              "..           ...      ...            ...            ...      ...   ...   \n",
              "532            5      139             64             35      140  28.6   \n",
              "533            1       96            122              0        0  22.4   \n",
              "534           10      101             86             37        0  45.6   \n",
              "535            0      141              0              0        0  42.4   \n",
              "536            0      125             96              0        0  22.5   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Diabetes  \n",
              "0                       0.260   22         0  \n",
              "1                       0.159   28         0  \n",
              "2                       0.365   24         1  \n",
              "3                       0.160   28         0  \n",
              "4                       0.183   33         0  \n",
              "..                        ...  ...       ...  \n",
              "532                     0.411   26         0  \n",
              "533                     0.207   27         0  \n",
              "534                     1.136   38         1  \n",
              "535                     0.205   29         1  \n",
              "536                     0.262   21         0  \n",
              "\n",
              "[537 rows x 9 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#데이터 가져오기\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "train_data=pd.read_csv('train.csv')\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "H_EjH3ZIqw5r",
        "outputId": "9e76f84b-574f-4d87-9235-a23e94d5cbe9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[  1.0000,  95.0000,  60.0000,  ...,  23.9000,   0.2600,  22.0000],\n",
            "        [  5.0000, 105.0000,  72.0000,  ...,  36.9000,   0.1590,  28.0000],\n",
            "        [  0.0000, 135.0000,  68.0000,  ...,  42.3000,   0.3650,  24.0000],\n",
            "        ...,\n",
            "        [ 10.0000, 101.0000,  86.0000,  ...,  45.6000,   1.1360,  38.0000],\n",
            "        [  0.0000, 141.0000,   0.0000,  ...,  42.4000,   0.2050,  29.0000],\n",
            "        [  0.0000, 125.0000,  96.0000,  ...,  22.5000,   0.2620,  21.0000]])\n",
            "tensor([[0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [0.]])\n"
          ]
        }
      ],
      "source": [
        "#데이터 가공\n",
        "x_train=train_data.copy()\n",
        "x_train=x_train.drop('Diabetes',axis=1)\n",
        "x_train = torch.FloatTensor(x_train.values)\n",
        "\n",
        "\n",
        "y_train=train_data['Diabetes'].copy()\n",
        "y_train = torch.FloatTensor(y_train.values)\n",
        "y_train=y_train.reshape(537,1)\n",
        "\n",
        "print(x_train)\n",
        "print(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ni7cMG2FrEa8",
        "outputId": "ee7a1961-7995-44fa-ec13-4cc530282a1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch    0/100000 Cost: 0.693147\n",
            "Epoch  100/100000 Cost: 0.632095\n",
            "Epoch  200/100000 Cost: 0.626077\n",
            "Epoch  300/100000 Cost: 0.624470\n",
            "Epoch  400/100000 Cost: 0.623757\n",
            "Epoch  500/100000 Cost: 0.623312\n",
            "Epoch  600/100000 Cost: 0.622986\n",
            "Epoch  700/100000 Cost: 0.622724\n",
            "Epoch  800/100000 Cost: 0.622504\n",
            "Epoch  900/100000 Cost: 0.622311\n",
            "Epoch 1000/100000 Cost: 0.622137\n",
            "Epoch 1100/100000 Cost: 0.621976\n",
            "Epoch 1200/100000 Cost: 0.621825\n",
            "Epoch 1300/100000 Cost: 0.621682\n",
            "Epoch 1400/100000 Cost: 0.621545\n",
            "Epoch 1500/100000 Cost: 0.621413\n",
            "Epoch 1600/100000 Cost: 0.621287\n",
            "Epoch 1700/100000 Cost: 0.621164\n",
            "Epoch 1800/100000 Cost: 0.621045\n",
            "Epoch 1900/100000 Cost: 0.620930\n",
            "Epoch 2000/100000 Cost: 0.620818\n",
            "Epoch 2100/100000 Cost: 0.620709\n",
            "Epoch 2200/100000 Cost: 0.620603\n",
            "Epoch 2300/100000 Cost: 0.620500\n",
            "Epoch 2400/100000 Cost: 0.620400\n",
            "Epoch 2500/100000 Cost: 0.620303\n",
            "Epoch 2600/100000 Cost: 0.620208\n",
            "Epoch 2700/100000 Cost: 0.620116\n",
            "Epoch 2800/100000 Cost: 0.620026\n",
            "Epoch 2900/100000 Cost: 0.619939\n",
            "Epoch 3000/100000 Cost: 0.619854\n",
            "Epoch 3100/100000 Cost: 0.619771\n",
            "Epoch 3200/100000 Cost: 0.619690\n",
            "Epoch 3300/100000 Cost: 0.619611\n",
            "Epoch 3400/100000 Cost: 0.619534\n",
            "Epoch 3500/100000 Cost: 0.619459\n",
            "Epoch 3600/100000 Cost: 0.619386\n",
            "Epoch 3700/100000 Cost: 0.619315\n",
            "Epoch 3800/100000 Cost: 0.619246\n",
            "Epoch 3900/100000 Cost: 0.619178\n",
            "Epoch 4000/100000 Cost: 0.619112\n",
            "Epoch 4100/100000 Cost: 0.619047\n",
            "Epoch 4200/100000 Cost: 0.618984\n",
            "Epoch 4300/100000 Cost: 0.618923\n",
            "Epoch 4400/100000 Cost: 0.618863\n",
            "Epoch 4500/100000 Cost: 0.618804\n",
            "Epoch 4600/100000 Cost: 0.618747\n",
            "Epoch 4700/100000 Cost: 0.618691\n",
            "Epoch 4800/100000 Cost: 0.618636\n",
            "Epoch 4900/100000 Cost: 0.618583\n",
            "Epoch 5000/100000 Cost: 0.618530\n",
            "Epoch 5100/100000 Cost: 0.618479\n",
            "Epoch 5200/100000 Cost: 0.618429\n",
            "Epoch 5300/100000 Cost: 0.618380\n",
            "Epoch 5400/100000 Cost: 0.618332\n",
            "Epoch 5500/100000 Cost: 0.618285\n",
            "Epoch 5600/100000 Cost: 0.618239\n",
            "Epoch 5700/100000 Cost: 0.618194\n",
            "Epoch 5800/100000 Cost: 0.618150\n",
            "Epoch 5900/100000 Cost: 0.618107\n",
            "Epoch 6000/100000 Cost: 0.618065\n",
            "Epoch 6100/100000 Cost: 0.618024\n",
            "Epoch 6200/100000 Cost: 0.617983\n",
            "Epoch 6300/100000 Cost: 0.617943\n",
            "Epoch 6400/100000 Cost: 0.617904\n",
            "Epoch 6500/100000 Cost: 0.617866\n",
            "Epoch 6600/100000 Cost: 0.617828\n",
            "Epoch 6700/100000 Cost: 0.617791\n",
            "Epoch 6800/100000 Cost: 0.617755\n",
            "Epoch 6900/100000 Cost: 0.617719\n",
            "Epoch 7000/100000 Cost: 0.617684\n",
            "Epoch 7100/100000 Cost: 0.617650\n",
            "Epoch 7200/100000 Cost: 0.617616\n",
            "Epoch 7300/100000 Cost: 0.617582\n",
            "Epoch 7400/100000 Cost: 0.617550\n",
            "Epoch 7500/100000 Cost: 0.617518\n",
            "Epoch 7600/100000 Cost: 0.617486\n",
            "Epoch 7700/100000 Cost: 0.617455\n",
            "Epoch 7800/100000 Cost: 0.617424\n",
            "Epoch 7900/100000 Cost: 0.617394\n",
            "Epoch 8000/100000 Cost: 0.617364\n",
            "Epoch 8100/100000 Cost: 0.617335\n",
            "Epoch 8200/100000 Cost: 0.617306\n",
            "Epoch 8300/100000 Cost: 0.617278\n",
            "Epoch 8400/100000 Cost: 0.617250\n",
            "Epoch 8500/100000 Cost: 0.617222\n",
            "Epoch 8600/100000 Cost: 0.617195\n",
            "Epoch 8700/100000 Cost: 0.617168\n",
            "Epoch 8800/100000 Cost: 0.617141\n",
            "Epoch 8900/100000 Cost: 0.617115\n",
            "Epoch 9000/100000 Cost: 0.617089\n",
            "Epoch 9100/100000 Cost: 0.617063\n",
            "Epoch 9200/100000 Cost: 0.617038\n",
            "Epoch 9300/100000 Cost: 0.617013\n",
            "Epoch 9400/100000 Cost: 0.616989\n",
            "Epoch 9500/100000 Cost: 0.616964\n",
            "Epoch 9600/100000 Cost: 0.616940\n",
            "Epoch 9700/100000 Cost: 0.616916\n",
            "Epoch 9800/100000 Cost: 0.616893\n",
            "Epoch 9900/100000 Cost: 0.616870\n",
            "Epoch 10000/100000 Cost: 0.616846\n",
            "Epoch 10100/100000 Cost: 0.616824\n",
            "Epoch 10200/100000 Cost: 0.616801\n",
            "Epoch 10300/100000 Cost: 0.616779\n",
            "Epoch 10400/100000 Cost: 0.616756\n",
            "Epoch 10500/100000 Cost: 0.616734\n",
            "Epoch 10600/100000 Cost: 0.616713\n",
            "Epoch 10700/100000 Cost: 0.616691\n",
            "Epoch 10800/100000 Cost: 0.616670\n",
            "Epoch 10900/100000 Cost: 0.616649\n",
            "Epoch 11000/100000 Cost: 0.616627\n",
            "Epoch 11100/100000 Cost: 0.616607\n",
            "Epoch 11200/100000 Cost: 0.616586\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32md:\\OneDrive\\학교\\4-2\\인공지능\\실습\\4주차\\1. 당뇨병 환자 예측\\당뇨.ipynb 셀 4\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/%ED%95%99%EA%B5%90/4-2/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%8B%A4%EC%8A%B5/4%EC%A3%BC%EC%B0%A8/1.%20%EB%8B%B9%EB%87%A8%EB%B3%91%20%ED%99%98%EC%9E%90%20%EC%98%88%EC%B8%A1/%EB%8B%B9%EB%87%A8.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/%ED%95%99%EA%B5%90/4-2/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%8B%A4%EC%8A%B5/4%EC%A3%BC%EC%B0%A8/1.%20%EB%8B%B9%EB%87%A8%EB%B3%91%20%ED%99%98%EC%9E%90%20%EC%98%88%EC%B8%A1/%EB%8B%B9%EB%87%A8.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m cost\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/OneDrive/%ED%95%99%EA%B5%90/4-2/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%8B%A4%EC%8A%B5/4%EC%A3%BC%EC%B0%A8/1.%20%EB%8B%B9%EB%87%A8%EB%B3%91%20%ED%99%98%EC%9E%90%20%EC%98%88%EC%B8%A1/%EB%8B%B9%EB%87%A8.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/%ED%95%99%EA%B5%90/4-2/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%8B%A4%EC%8A%B5/4%EC%A3%BC%EC%B0%A8/1.%20%EB%8B%B9%EB%87%A8%EB%B3%91%20%ED%99%98%EC%9E%90%20%EC%98%88%EC%B8%A1/%EB%8B%B9%EB%87%A8.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m \u001b[39m100\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/%ED%95%99%EA%B5%90/4-2/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%8B%A4%EC%8A%B5/4%EC%A3%BC%EC%B0%A8/1.%20%EB%8B%B9%EB%87%A8%EB%B3%91%20%ED%99%98%EC%9E%90%20%EC%98%88%EC%B8%A1/%EB%8B%B9%EB%87%A8.ipynb#X15sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEpoch \u001b[39m\u001b[39m{:4d}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m Cost: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/%ED%95%99%EA%B5%90/4-2/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%8B%A4%EC%8A%B5/4%EC%A3%BC%EC%B0%A8/1.%20%EB%8B%B9%EB%87%A8%EB%B3%91%20%ED%99%98%EC%9E%90%20%EC%98%88%EC%B8%A1/%EB%8B%B9%EB%87%A8.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m         epoch, nb_epochs, cost\u001b[39m.\u001b[39mitem()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/OneDrive/%ED%95%99%EA%B5%90/4-2/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5/%EC%8B%A4%EC%8A%B5/4%EC%A3%BC%EC%B0%A8/1.%20%EB%8B%B9%EB%87%A8%EB%B3%91%20%ED%99%98%EC%9E%90%20%EC%98%88%EC%B8%A1/%EB%8B%B9%EB%87%A8.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     ))\n",
            "File \u001b[1;32mc:\\Users\\bjw01\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:112\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m obj, \u001b[39m*\u001b[39m_ \u001b[39m=\u001b[39m args\n\u001b[0;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m--> 112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mprofiler\u001b[39m.\u001b[39;49mrecord_function(profile_name):\n\u001b[0;32m    113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\bjw01\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\profiler.py:443\u001b[0m, in \u001b[0;36mrecord_function.__init__\u001b[1;34m(self, name, args)\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_callbacks_on_exit: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    441\u001b[0m \u001b[39m# Stores underlying RecordFunction as a tensor. TODO: move to custom\u001b[39;00m\n\u001b[0;32m    442\u001b[0m \u001b[39m# class (https://github.com/pytorch/pytorch/issues/35026).\u001b[39;00m\n\u001b[1;32m--> 443\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mzeros(\u001b[39m1\u001b[39;49m)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 모델 초기화\n",
        "W = torch.zeros((8, 1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "\n",
        "optimizer = optim.SGD([W, b], lr=1e-4)\n",
        "\n",
        "nb_epochs = 100000\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "    hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "    loss=torch.nn.BCELoss()\n",
        "    cost=loss(hypothesis,y_train)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "UfzjjvUiwBwi",
        "outputId": "851ed64a-d554-48c6-986c-a3e8f6f170d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True],\n",
            "        [True]])\n",
            "The model has an accuracy of 100.00% for the training set.\n"
          ]
        }
      ],
      "source": [
        "#데이터 평가\n",
        "hypothesis = torch.sigmoid(x_train.matmul(W) + b)\n",
        "\n",
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "\n",
        "correct_prediction = prediction.float() == y_train\n",
        "print(correct_prediction[:5])\n",
        "\n",
        "accuracy = correct_prediction.sum().item() / len(correct_prediction)\n",
        "print('The model has an accuracy of {:2.2f}% for the training set.'.format(accuracy * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data=pd.read_csv('test.csv')\n",
        "test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_test = torch.FloatTensor(x_train.values)\n",
        "hypothesis = torch.sigmoid(x_test.matmul(W) + b)\n",
        "prediction = hypothesis >= torch.FloatTensor([0.5])\n",
        "print(prediction)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "5b31e8577c3492df978c98dac6179edf3340b968ce45f9e225a7705115bba9be"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
